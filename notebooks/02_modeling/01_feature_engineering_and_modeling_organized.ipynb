{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bus Duration Prediction: Feature Engineering and Modeling\n",
    "\n",
    "This notebook contains the feature engineering process and model development for predicting bus journey durations.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Data Loading and Preprocessing](#data)\n",
    "3. [Feature Engineering](#features)\n",
    "   - Basic Features\n",
    "   - Weather Features\n",
    "   - Time-based Features\n",
    "   - Advanced Feature Engineering\n",
    "4. [Model Development](#modeling)\n",
    "   - Data Splitting\n",
    "   - Model Training\n",
    "   - Model Evaluation\n",
    "   - Stacking Ensemble\n",
    "5. [Model Interpretability](#interpretability)\n",
    "6. [Model Deployment](#deployment)\n",
    "7. [Results Analysis](#results)\n",
    "   - Feature Importance\n",
    "   - Performance Metrics\n",
    "   - Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## 1. Setup and Imports\n",
    "\n",
    "Import required libraries and set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib._api' has no attribute 'MatplotlibDeprecationWarning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Import custom utility functions\u001b[39;00m\n",
      "File \u001b[1;32me:\\bus-schedule-app\\.venv\\Lib\\site-packages\\matplotlib\\pyplot.py:55\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcycler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycler  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolorbar\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n",
      "File \u001b[1;32me:\\bus-schedule-app\\.venv\\Lib\\site-packages\\matplotlib\\colorbar.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, collections, cm, colors, contour, ticker\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martist\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmartist\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpatches\u001b[39;00m\n",
      "File \u001b[1;32me:\\bus-schedule-app\\.venv\\Lib\\site-packages\\matplotlib\\cbook.py:369\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    364\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<an empty list>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_local_over_kwdict\u001b[39m(\n\u001b[0;32m    368\u001b[0m         local_var, kwargs, \u001b[38;5;241m*\u001b[39mkeys,\n\u001b[1;32m--> 369\u001b[0m         warning_cls\u001b[38;5;241m=\u001b[39m\u001b[43m_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMatplotlibDeprecationWarning\u001b[49m):\n\u001b[0;32m    370\u001b[0m     out \u001b[38;5;241m=\u001b[39m local_var\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib._api' has no attribute 'MatplotlibDeprecationWarning'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import custom utility functions\n",
    "import sys\n",
    "sys.path.append('../analysis_src')\n",
    "from model_utils import (\n",
    "    dataframe_info,\n",
    "    create_cyclical_features,\n",
    "    evaluate_model,\n",
    "    select_features,\n",
    "    plot_feature_importance,\n",
    "    tune_hyperparameters,\n",
    "    analyze_predictions,\n",
    "    plot_learning_curves,\n",
    "    create_error_analysis\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "## 2. Data Loading and Preprocessing\n",
    "\n",
    "Load the preprocessed data and perform any necessary cleaning or transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "train_data = pd.read_csv('../data/processed/train_data.csv')\n",
    "test_data = pd.read_csv('../data/processed/test_data.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"\\nFeature information:\")\n",
    "dataframe_info(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='features'></a>\n",
    "## 3. Feature Engineering\n",
    "\n",
    "Create and transform features for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Basic Features\n",
    "\n",
    "Process route, distance, and other basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating basic features...\")\n",
    "# Calculate distances, speeds, etc.\n",
    "train_data['avg_speed'] = train_data['distance'] / train_data['duration']\n",
    "train_data['stops_per_km'] = train_data['num_stops'] / train_data['distance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Weather Features\n",
    "\n",
    "Process and engineer weather-related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather feature processing code here\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Time-based Features\n",
    "\n",
    "Create cyclical time features and time-based aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCreating time-based features...\")\n",
    "# Extract time components\n",
    "train_data['hour'] = pd.to_datetime(train_data['departure_time']).dt.hour\n",
    "train_data['day_of_week'] = pd.to_datetime(train_data['departure_date']).dt.dayofweek\n",
    "train_data['month'] = pd.to_datetime(train_data['departure_date']).dt.month\n",
    "\n",
    "# Create cyclical features for time components\n",
    "print(\"Creating cyclical features...\")\n",
    "train_data['hour_sin'], train_data['hour_cos'] = create_cyclical_features(train_data, 'hour', 24)\n",
    "train_data['day_sin'], train_data['day_cos'] = create_cyclical_features(train_data, 'day_of_week', 7)\n",
    "train_data['month_sin'], train_data['month_cos'] = create_cyclical_features(train_data, 'month', 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather Features (if available)\n",
    "if 'temperature' in train_data.columns and 'precipitation' in train_data.columns:\n",
    "    print(\"\\nProcessing weather features...\")\n",
    "    # Bin temperature into categories\n",
    "    train_data['temp_category'] = pd.qcut(train_data['temperature'], q=5, labels=['Very Cold', 'Cold', 'Moderate', 'Warm', 'Hot'])\n",
    "    \n",
    "    # Create precipitation categories\n",
    "    train_data['weather_condition'] = np.where(train_data['precipitation'] == 0, 'Clear',\n",
    "                                    np.where(train_data['precipitation'] < 2.5, 'Light Rain',\n",
    "                                    np.where(train_data['precipitation'] < 7.6, 'Moderate Rain', 'Heavy Rain')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "print(\"\\nSelecting most important features...\")\n",
    "feature_cols = [col for col in train_data.columns if col not in ['duration', 'departure_time', 'departure_date']]\n",
    "X = train_data[feature_cols]\n",
    "y = train_data['duration']\n",
    "\n",
    "# Select top features using f_regression\n",
    "X_selected, selected_features = select_features(X, y, method='f_regression', k=15)\n",
    "print(\"\\nTop 15 selected features:\", selected_features)\n",
    "\n",
    "# Display feature information\n",
    "print(\"\\nFeature information after engineering:\")\n",
    "feature_info = dataframe_info(X_selected)\n",
    "display(feature_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating advanced features...\")\n",
    "\n",
    "# Create interaction features\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns\n",
    "feature_pairs = [\n",
    "    ('distance', 'num_stops'),\n",
    "    ('avg_speed', 'stops_per_km'),\n",
    "    ('hour', 'day_of_week')\n",
    "]\n",
    "\n",
    "X_advanced = create_interaction_features(X, feature_pairs)\n",
    "\n",
    "# Create polynomial features for key metrics\n",
    "poly_features = ['distance', 'avg_speed', 'stops_per_km']\n",
    "X_advanced = create_polynomial_features(X_advanced, poly_features, degree=2)\n",
    "\n",
    "# Create lag features if we have time-series data\n",
    "if 'departure_time' in train_data.columns:\n",
    "    print(\"\\nCreating time-based lag features...\")\n",
    "    lag_features = ['duration', 'avg_speed']\n",
    "    group_columns = ['route_id'] if 'route_id' in train_data.columns else None\n",
    "    X_advanced = create_lag_features(\n",
    "        X_advanced, \n",
    "        lag_features,\n",
    "        'departure_time',\n",
    "        group_columns=group_columns\n",
    "    )\n",
    "\n",
    "# Update feature selection with new features\n",
    "X_selected, selected_features = select_features(X_advanced, y, method='f_regression', k=20)\n",
    "print(\"\\nSelected features after advanced engineering:\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='modeling'></a>\n",
    "## 4. Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Data Splitting\n",
    "\n",
    "Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Splitting data into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Model Training\n",
    "\n",
    "Train and compare different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42),\n",
    "    'KNN': KNeighborsRegressor(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "print(\"\\nTraining and evaluating models...\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    metrics = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "    results[name] = metrics\n",
    "    \n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"Train RMSE: {metrics['rmse_train']:.2f}\")\n",
    "    print(f\"Test RMSE: {metrics['rmse_test']:.2f}\")\n",
    "    print(f\"R² Score (Test): {metrics['r2_test']:.4f}\")\n",
    "    \n",
    "    # Plot feature importance for tree-based models\n",
    "    if name in ['Random Forest', 'XGBoost']:\n",
    "        print(f\"\\n{name} Feature Importance:\")\n",
    "        plot_feature_importance(model, selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results summary\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Comparison:\")\n",
    "display(results_df)\n",
    "\n",
    "# Find best model\n",
    "best_model = min(results.items(), key=lambda x: x[1]['rmse_test'])\n",
    "print(f\"\\nBest Model: {best_model[0]}\")\n",
    "print(f\"Test RMSE: {best_model[1]['rmse_test']:.2f}\")\n",
    "print(f\"R² Score: {best_model[1]['r2_test']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Model Evaluation\n",
    "\n",
    "Evaluate model performance using various metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation code here\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCreating stacking ensemble...\")\n",
    "\n",
    "# Define base models with tuned hyperparameters\n",
    "base_models = {\n",
    "    'rf': best_rf,\n",
    "    'xgb': best_xgb,\n",
    "    'knn': KNeighborsRegressor(n_neighbors=5),\n",
    "    'ridge': Ridge(alpha=1.0)\n",
    "}\n",
    "\n",
    "# Use LightGBM as meta-learner\n",
    "from lightgbm import LGBMRegressor\n",
    "meta_model = LGBMRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create stacking ensemble\n",
    "stacking_model, meta_train, meta_test = create_stacking_ensemble(\n",
    "    base_models,\n",
    "    meta_model,\n",
    "    X_selected,\n",
    "    y,\n",
    "    X_test\n",
    ")\n",
    "\n",
    "# Evaluate stacking ensemble\n",
    "print(\"\\nEvaluating stacking ensemble...\")\n",
    "analyze_predictions(stacking_model, meta_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='interpretability'></a>\n",
    "## Model Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAnalyzing feature importance using SHAP values...\")\n",
    "analyze_feature_importance_shap(best_rf, X_test, max_display=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='deployment'></a>\n",
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPreparing model for deployment...\")\n",
    "\n",
    "# Save model artifacts\n",
    "save_model_artifacts(\n",
    "    best_rf,\n",
    "    selected_features,\n",
    "    output_dir='model_artifacts'\n",
    ")\n",
    "\n",
    "# Generate FastAPI application\n",
    "api_code = create_prediction_api()\n",
    "\n",
    "# Save API code\n",
    "with open('app.py', 'w') as f:\n",
    "    f.write(api_code)\n",
    "\n",
    "print(\"\\nModel artifacts saved and API code generated.\")\n",
    "print(\"To deploy the model:\")\n",
    "print(\"1. Install requirements: pip install fastapi uvicorn\")\n",
    "print(\"2. Start the API: uvicorn app:app --reload\")\n",
    "print(\"3. Access the API documentation at http://localhost:8000/docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nModel Development Summary:\")\n",
    "print(\"1. Advanced Feature Engineering:\")\n",
    "print(f\"   - Created {len(X_advanced.columns) - len(X.columns)} new features\")\n",
    "print(f\"   - Selected top {len(selected_features)} features\")\n",
    "\n",
    "print(\"\\n2. Model Performance:\")\n",
    "print(\"   Base Models:\")\n",
    "for name, metrics in final_results.items():\n",
    "    print(f\"   - {name}: RMSE = {metrics['rmse_test']:.2f}, R² = {metrics['r2_test']:.4f}\")\n",
    "print(f\"\\n   Stacking Ensemble:\")\n",
    "ensemble_metrics = evaluate_model(stacking_model, meta_train, meta_test, y_train, y_test)\n",
    "print(f\"   - RMSE = {ensemble_metrics['rmse_test']:.2f}, R² = {ensemble_metrics['r2_test']:.4f}\")\n",
    "\n",
    "print(\"\\n3. Deployment:\")\n",
    "print(\"   - Model artifacts saved in 'model_artifacts' directory\")\n",
    "print(\"   - FastAPI application generated in 'app.py'\")\n",
    "print(\"   - Ready for deployment with feature scaling and validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='results'></a>\n",
    "## 5. Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Feature Importance\n",
    "\n",
    "Analyze which features contribute most to the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis code here\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Performance Metrics\n",
    "\n",
    "Detailed analysis of model performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics analysis code here\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Visualizations\n",
    "\n",
    "Visualize model predictions and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization code here\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
